sample and train:
ploss weighted normal smooth 2 500 66.66, 62.37, 61.58, 60.67, 68.92, 62.09, 61.63, 62.54
ploss weighted normal smooth 10 500 50.33, 62.88, 56.32, 63.55, 47.11, 55.02, 60.22

ploss weighted normal smooth 10 500 ntest 58.36, 58.53, 51.92, 59.15
ploss weighted normal smooth 2 500 ntest 65.93, 54.12, 60.22, 65.42, 65.19

p1 ploss weighted normal smooth 10 1000 ntest 73.55, 74.68, 75.53, 73.78, 75.64, 72.88
p1 ploss weighted normal smooth 2 1000 ntest 78.58, 76.44, 77.74, 79.60, 78.41, 78.13, 77.23, 80.00, 78.41

perceptual loss:
p1 weighted normal smooth 2 1000 ntest 78.58, 76.44, 77.74, 79.60, 78.41, 78.13,      77.23, 80.00, 78.41
p2 weighted normal smooth 2 1000 ntest 76.94, 75.59, 75.31, 76.66, 76.10, 75.93
p3 weighted normal smooth 2 1000 ntest 76.27, 74.23, 73.50, 73.33, 75.87, 76.04
p4 weighted normal smooth 2 1000 ntest 71.69, 71.58, 71.63, 75.36, 73.89, 76.61
p5 weighted normal smooth 2 1000 ntest 79.20, 79.60, 79.94, 78.30, 81.69, 77.51
p6 weighted normal smooth 2 1000 ntest 88.70, 87.06, 87.79, 89.66, 87.68, 88.24
p7 weighted normal smooth 2 1000 ntest 80.22, 80.73, 82.09, 80.96, 79.66, 82.14,      82.25
p8 weighted normal smooth 2 1000 ntest 1.00
p9 weighted normal smooth 2 1000 ntest 64.57, 59.37, 60.25, 66.27, 60.62, 62.76

p1  => (0.035248,0.009095)
p2  => (0.067340,0.013359)
p3  => (0.083997,0.014106)
p4  => (0.015855,0.004911)
p5  => (0.028645,0.024008)
p6  => (0.003901,-0.025030)
p7  => (0.019294,0.003616)
p8  => (0.012175,-0.006620)
p9  => (0.009073,0.010001)

with [Y]
p1  => (0.109729,0.015547)
p2  => (0.127342,0.015777)
p3  => (0.111500,0.017272)
p4  => (0.021656,0.004611)
p5  => (0.080230,0.042193)
p6  => (0.356482,0.326489)
p7  => (0.077205,0.008525)
p8  => (0.756882,0.675377)
p9  => (0.009761,0.008870)

with huber loss:
p1 d=0.35 72.71, 67.96, 69.70, 69.77, 72.14, 72.09, 68.58, 71.97
p9 d=0.5 57.40, 53.78, 56.44, 51.41, 56.38
p9 d=5.0 40.39, 43.84, 49.83, 50.00
p9 d=0.35 57.40, 47.11, 57.23, 49.37, 46.55, 50.11, 46.94, 56.10, 49.54, 48.58, 51.29, 60.39

p9 uw d=0.35 1.0 ?

BCE loss:
p1 45.53, 46.55, 44.12, 48.81, 45.59    => (0.004761,0.002452)      [Y]=> (0.005837,0.001931)
p2 51.92, 52.59, 54.68, 55.81, 51.18    => (0.002842,0.002388)      [Y]=> (0.001218,0.000238)
p3 53.22, 49.26, 48.87, 46.83, 49.94    => (0.014960,0.002175)      [Y]=> (0.007423,0.000945)
p4 56.10, 56.38, 55.14, 55.53, 57.68    => (0.029511,0.008865)      [Y]=> (0.017198,-0.001093)
p5 42.54, 45.02, 45.70, 44.68, 45.76    => (-0.000978,0.006210)     [Y]=> (-0.001723,0.003122)
p6 53.38, 49.77, 51.12, 53.61, 58.53    => (0.016137,0.009400)      [Y]=> (0.015125,0.008388)
p7 50.33, 48.64, 57.74, 49.49, 51.80    => (0.007805,-0.001330)     [Y]=> (0.006882,-0.003232)
p8 47.17, 51.80, 53.89, 51.97, 49.66    => (0.010588,0.002187)      [Y]=> (0.010795,0.001783)
p9 57.06, 54.85, 56.27, 55.81, 57.40    => (0.006627,0.005940)      [Y]=> (0.005305,0.003668)

New Data:
RTGAN Adv. + Charb. (10−3, 1) 1.0 0.92183 0.75456
RTGAN Adv. + Charb. (10−2, 1) 1.0 0.90271 0.70295